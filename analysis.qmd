---
title: "Bavarian Fishing Exam - Free Spots Analysis"
subtitle: "Tracking exam availability across locations"
author: "Automated Analysis"
date: now
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    code-fold: true
    code-summary: "Show code"
    embed-resources: true
    page-layout: full
    fig-width: 14
    fig-height: 8
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
#| include: false

# Load required libraries
library(data.table)
library(ggplot2)
library(lubridate)
library(jsonlite)
library(knitr)

# Set default theme
theme_set(theme_minimal(base_size = 12))
```

## Overview

This dashboard shows the availability of free spots for the Bavarian fishing examination across different locations over time. Data is automatically scraped every 2 hours from the [official website](https://fischerpruefung-online.bayern.de/).

```{r load-data}
# Find all JSON files in the data directory, excluding latest.json
json_files <- list.files("data", pattern = "exam-data-.*\\.json$", full.names = TRUE)
json_files <- json_files[basename(json_files) != "latest.json"]

cat("Processing", length(json_files), "JSON files...\n")

# Initialize empty list to store results
all_data <- list()

# Process each JSON file
for (json_file in json_files) {
  # Read JSON file
  data <- tryCatch({
    fromJSON(json_file)
  }, error = function(e) {
    return(NULL)
  })

  # Skip if data is NULL or missing required fields
  if (is.null(data) || is.null(data$scraped_at) ||
      is.null(data$exam_appointments) || length(data$exam_appointments) == 0) {
    next
  }

  # Extract scrape date from JSON
  scrape_date <- as.POSIXct(data$scraped_at, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")

  # Convert to data.table
  appointments <- as.data.table(data$exam_appointments)

  # Add scrape date
  appointments[, scrape_date := scrape_date]

  # Calculate free spots
  appointments[, free_spots := as.numeric(max_participants) - as.numeric(current_participants)]

  # Store in list
  all_data[[json_file]] <- appointments
}

# Combine all data
dt <- rbindlist(all_data, fill = TRUE)

# Aggregate by location and scrape date
dt_agg <- dt[, .(
  total_free_spots = sum(free_spots, na.rm = TRUE),
  total_appointments = .N
), by = .(location, scrape_date)]

# Sort by scrape date
setorder(dt_agg, scrape_date)
```

## Key Statistics

```{r summary-stats}
#| results: asis

total_scrapes <- uniqueN(dt_agg$scrape_date)
total_locations <- uniqueN(dt_agg$location)
date_range_start <- format(min(dt_agg$scrape_date), "%Y-%m-%d %H:%M")
date_range_end <- format(max(dt_agg$scrape_date), "%Y-%m-%d %H:%M")
total_observations <- nrow(dt_agg)

cat(sprintf("- **Total data points:** %d scrapes across %d locations\n", total_scrapes, total_locations))
cat(sprintf("- **Date range:** %s to %s (UTC)\n", date_range_start, date_range_end))
cat(sprintf("- **Total observations:** %s location-time combinations\n", format(total_observations, big.mark = ",")))
```

## Free Spots Over Time - All Locations

This chart shows the number of free exam spots across all tracked locations over time.

```{r plot-all-locations}
#| fig-cap: "Free exam spots over time by location"

p1 <- ggplot(dt_agg, aes(x = scrape_date, y = total_free_spots, color = location, group = location)) +
  geom_line(linewidth = 0.8, alpha = 0.7) +
  geom_point(size = 1.5, alpha = 0.6) +
  labs(
    title = "Free Exam Spots Over Time by Location",
    subtitle = "All tracked locations",
    x = "Date",
    y = "Number of Free Spots",
    color = "Location"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    plot.subtitle = element_text(size = 14, color = "gray40"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right",
    legend.text = element_text(size = 9),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white"),
    plot.background = element_rect(fill = "white")
  ) +
  scale_x_datetime(date_breaks = "3 days", date_labels = "%b %d") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10))

print(p1)

# Save plot
ggsave("plots/free_spots_by_location.png", p1, width = 16, height = 10, dpi = 300, bg = "white")
```

## Top 10 Locations by Average Free Spots

Focusing on locations with the highest average availability.

```{r plot-top10}
#| fig-cap: "Top 10 locations with most available spots"

# Calculate top locations
top_locations <- dt_agg[, .(avg_free_spots = mean(total_free_spots)), by = location][
  order(-avg_free_spots)
][1:min(10, .N)]

dt_top <- dt_agg[location %in% top_locations$location]

p2 <- ggplot(dt_top, aes(x = scrape_date, y = total_free_spots, color = location, group = location)) +
  geom_line(linewidth = 1.2, alpha = 0.8) +
  geom_point(size = 2.5, alpha = 0.7) +
  labs(
    title = "Free Exam Spots Over Time - Top 10 Locations",
    subtitle = "Locations with highest average free spots",
    x = "Date",
    y = "Number of Free Spots",
    color = "Location"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    plot.subtitle = element_text(size = 14, color = "gray40"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right",
    legend.text = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white"),
    plot.background = element_rect(fill = "white")
  ) +
  scale_x_datetime(date_breaks = "3 days", date_labels = "%b %d") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10))

print(p2)

# Save plot
ggsave("plots/free_spots_top10_locations.png", p2, width = 16, height = 10, dpi = 300, bg = "white")
```

## Location Summary Table

Statistical summary showing minimum, average, and maximum free spots per location.

```{r summary-table}
# Create summary table
summary_table <- dt_agg[, .(
  min_free_spots = min(total_free_spots),
  avg_free_spots = round(mean(total_free_spots), 1),
  max_free_spots = max(total_free_spots),
  total_observations = .N
), by = location][order(-avg_free_spots)]

# Save CSV
fwrite(summary_table, "plots/location_summary.csv")

# Display table
kable(summary_table,
      col.names = c("Location", "Min Free Spots", "Avg Free Spots", "Max Free Spots", "Observations"),
      align = c("l", "r", "r", "r", "r"),
      caption = "Summary statistics by location")
```

---

*Data source: [fischerpruefung-online.bayern.de](https://fischerpruefung-online.bayern.de/)*
*Generated: `r format(Sys.time(), '%Y-%m-%d %H:%M:%S %Z')`*
