---
title: "Bavarian Fishing Exam - Free Spots Analysis"
subtitle: "Tracking exam availability across locations"
author: "Automated Analysis"
date: now
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    code-fold: true
    code-summary: "Show code"
    embed-resources: true
    page-layout: full
    fig-width: 14
    fig-height: 8
    output-file: index.html
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
#| include: false

# Load required libraries
library(data.table)
library(ggplot2)
library(lubridate)
library(jsonlite)
library(knitr)

# Set default theme
theme_set(theme_minimal(base_size = 12))
```

## Overview

This dashboard shows the availability of free spots for the Bavarian fishing examination across different locations over time. Data is automatically scraped every 2 hours from the [official website](https://fischerpruefung-online.bayern.de/).

```{r load-data}
# Find all JSON files in the data directory, excluding latest.json
json_files <- list.files("data", pattern = "exam-data-.*\\.json$", full.names = TRUE)
json_files <- json_files[basename(json_files) != "latest.json"]

cat("Processing", length(json_files), "JSON files...\n")

# Initialize empty list to store results
all_data <- list()

# Process each JSON file
for (json_file in json_files) {
  # Read JSON file
  data <- tryCatch({
    fromJSON(json_file)
  }, error = function(e) {
    return(NULL)
  })

  # Skip if data is NULL or missing required fields
  if (is.null(data) || is.null(data$scraped_at) ||
      is.null(data$exam_appointments) || length(data$exam_appointments) == 0) {
    next
  }

  # Extract scrape date from JSON
  scrape_date <- as.POSIXct(data$scraped_at, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")

  # Convert to data.table
  appointments <- as.data.table(data$exam_appointments)

  # Add scrape date
  appointments[, scrape_date := scrape_date]

  # Calculate free spots
  appointments[, free_spots := as.numeric(max_participants) - as.numeric(current_participants)]

  # Store in list
  all_data[[json_file]] <- appointments
}

# Combine all data
dt <- rbindlist(all_data, fill = TRUE)

# Create unique exam identifier (specific exam slot)
dt[, exam_id := paste(exam_date, exam_start_time, location, sep = " | ")]

# Keep only the columns we need for plotting
dt_agg <- dt[, .(exam_id, scrape_date, free_spots, region, location, exam_date, exam_start_time)]

# Remove any potential duplicates (same exam_id at same scrape_date)
dt_agg <- unique(dt_agg, by = c("exam_id", "scrape_date"))

# Sort by exam_id and scrape_date for proper line plotting
setorder(dt_agg, exam_id, scrape_date)
```

## Key Statistics

```{r summary-stats}
#| results: asis

total_scrapes <- uniqueN(dt_agg$scrape_date)
total_locations <- uniqueN(dt_agg$location)
date_range_start <- format(min(dt_agg$scrape_date), "%Y-%m-%d %H:%M")
date_range_end <- format(max(dt_agg$scrape_date), "%Y-%m-%d %H:%M")
total_observations <- nrow(dt_agg)

cat(sprintf("- **Total data points:** %d scrapes across %d locations\n", total_scrapes, total_locations))
cat(sprintf("- **Date range:** %s to %s (UTC)\n", date_range_start, date_range_end))
cat(sprintf("- **Total observations:** %s location-time combinations\n", format(total_observations, big.mark = ",")))
```

## Free Spots Over Time - All Locations

This chart shows the number of free exam spots across all tracked locations over time.

```{r plot-all-locations}
#| fig-cap: "Free spots for each exam appointment over time, split by region and location"
#| fig-height: 20

p1 <- ggplot(dt_agg, aes(x = scrape_date, y = free_spots, color = exam_id, group = exam_id)) +
  geom_line(linewidth = 0.8, alpha = 0.8) +
  geom_point(size = 1.5, alpha = 0.6) +
  facet_wrap(~ region + location, ncol = 3, scales = "free_y") +
  labs(
    title = "Free Spots Per Exam Appointment Over Time",
    subtitle = "Each line represents a specific exam (date + time), split by region and location",
    x = "Scrape Date & Time (UTC)",
    y = "Number of Free Spots"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 7),
    axis.text.y = element_text(size = 8),
    legend.position = "none",
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white"),
    plot.background = element_rect(fill = "white"),
    strip.text = element_text(size = 9, face = "bold")
  ) +
  scale_x_datetime(date_breaks = "12 hours",
                   date_minor_breaks = "2 hours",
                   date_labels = "%b %d\n%H:%M") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 6))

print(p1)

# Save plot
ggsave("plots/free_spots_by_location.png", p1, width = 18, height = 24, dpi = 300, bg = "white")
```

## Top 10 Locations by Average Free Spots

Focusing on locations with the highest average availability.

```{r plot-top10}
#| fig-cap: "Top 10 exam appointments with most available spots, split by region and location"
#| fig-height: 16

# Calculate top exams by average free spots
top_exams <- dt_agg[, .(avg_free_spots = mean(free_spots)), by = exam_id][
  order(-avg_free_spots)
][1:min(10, .N)]

dt_top <- dt_agg[exam_id %in% top_exams$exam_id]

p2 <- ggplot(dt_top, aes(x = scrape_date, y = free_spots, color = exam_id, group = exam_id)) +
  geom_line(linewidth = 1.2, alpha = 0.8) +
  geom_point(size = 2.0, alpha = 0.7) +
  facet_wrap(~ region + location, ncol = 3, scales = "free_y") +
  labs(
    title = "Free Spots Over Time - Top 10 Exam Appointments",
    subtitle = "Specific exam slots with highest average free spots, split by region and location",
    x = "Scrape Date & Time (UTC)",
    y = "Number of Free Spots"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8),
    axis.text.y = element_text(size = 9),
    legend.position = "none",
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white"),
    plot.background = element_rect(fill = "white"),
    strip.text = element_text(size = 10, face = "bold")
  ) +
  scale_x_datetime(date_breaks = "12 hours",
                   date_minor_breaks = "2 hours",
                   date_labels = "%b %d\n%H:%M") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 6))

print(p2)

# Save plot
ggsave("plots/free_spots_top10_locations.png", p2, width = 18, height = 20, dpi = 300, bg = "white")
```

## Exam Appointment Summary Table

Statistical summary showing minimum, average, and maximum free spots per exam appointment.

```{r summary-table}
# Create summary table for individual exams
summary_table <- dt_agg[, .(
  exam_date = first(exam_date),
  exam_time = first(exam_start_time),
  location = first(location),
  region = first(region),
  min_free_spots = min(free_spots),
  avg_free_spots = round(mean(free_spots), 1),
  max_free_spots = max(free_spots),
  observations = .N
), by = exam_id][order(-avg_free_spots)]

# Save CSV
fwrite(summary_table, "plots/location_summary.csv")

# Display top 20
kable(head(summary_table, 20),
      col.names = c("Exam ID", "Exam Date", "Time", "Location", "Region",
                    "Min", "Avg", "Max", "Obs"),
      align = c("l", "l", "l", "l", "l", "r", "r", "r", "r"),
      caption = "Top 20 exam appointments by average free spots")
```

---

*Data source: [fischerpruefung-online.bayern.de](https://fischerpruefung-online.bayern.de/)*
*Generated: `r format(Sys.time(), '%Y-%m-%d %H:%M:%S %Z')`*
